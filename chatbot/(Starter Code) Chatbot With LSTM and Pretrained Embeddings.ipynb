{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJAWnBFlkE2w"
   },
   "source": [
    "# LSTM Bot\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this project, you will build a chatbot that can converse with you at the command line. The chatbot will use a Sequence to Sequence text generation architecture with an LSTM as it's memory unit. You will also learn to use pretrained word embeddings to improve the performance of the model. At the conclusion of the project, you will be able to show your chatbot to potential employers.\n",
    "\n",
    "Additionally, you have the option to use pretrained word embeddings in your model. We have loaded Brown Embeddings from Gensim in the starter code below. You can compare the performance of your model with pre-trained embeddings against a model without the embeddings.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "A sequence to sequence model (Seq2Seq) has two components:\n",
    "- An Encoder consisting of an embedding layer and LSTM unit.\n",
    "- A Decoder consisting of an embedding layer, LSTM unit, and linear output unit.\n",
    "\n",
    "The Seq2Seq model works by accepting an input into the Encoder, passing the hidden state from the Encoder to the Decoder, which the Decoder uses to output a series of token predictions.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- Pytorch\n",
    "- Numpy\n",
    "- Pandas\n",
    "- NLTK\n",
    "- Gzip\n",
    "- Gensim\n",
    "\n",
    "\n",
    "Please choose a dataset from the Torchtext website. We recommend looking at the Squad dataset first. Here is a link to the website where you can view your options:\n",
    "\n",
    "- https://pytorch.org/text/stable/datasets.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.0.0-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
      "Collecting torchdata\n",
      "  Using cached torchdata-0.6.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Collecting torchtext\n",
      "  Using cached torchtext-0.15.1-cp38-cp38-manylinux1_x86_64.whl (2.0 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Requirement already satisfied: typing-extensions in /home/kach271771/Desktop/pythonenvs/lstm/lib/python3.8/site-packages (from torch) (4.5.0)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91\n",
      "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Collecting triton==2.0.0\n",
      "  Using cached triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "Requirement already satisfied: jinja2 in /home/kach271771/Desktop/pythonenvs/lstm/lib/python3.8/site-packages (from torch) (3.1.2)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.10.3-py3-none-any.whl (10 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91\n",
      "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3\n",
      "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.0-py3-none-any.whl (2.0 MB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "Requirement already satisfied: setuptools in /home/kach271771/Desktop/pythonenvs/lstm/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\n",
      "Requirement already satisfied: wheel in /home/kach271771/Desktop/pythonenvs/lstm/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Collecting cmake\n",
      "  Using cached cmake-3.26.1-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "Collecting lit\n",
      "  Using cached lit-16.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /home/kach271771/Desktop/pythonenvs/lstm/lib/python3.8/site-packages (from torchdata) (2.28.2)\n",
      "Requirement already satisfied: urllib3>=1.25 in /home/kach271771/Desktop/pythonenvs/lstm/lib/python3.8/site-packages (from torchdata) (1.26.15)\n",
      "Requirement already satisfied: numpy in /home/kach271771/Desktop/pythonenvs/lstm/lib/python3.8/site-packages (from torchtext) (1.24.2)\n",
      "Requirement already satisfied: tqdm in /home/kach271771/Desktop/pythonenvs/lstm/lib/python3.8/site-packages (from torchtext) (4.65.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/kach271771/Desktop/pythonenvs/lstm/lib/python3.8/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kach271771/Desktop/pythonenvs/lstm/lib/python3.8/site-packages (from requests->torchdata) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kach271771/Desktop/pythonenvs/lstm/lib/python3.8/site-packages (from requests->torchdata) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kach271771/Desktop/pythonenvs/lstm/lib/python3.8/site-packages (from requests->torchdata) (2022.12.7)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, lit, cmake, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, networkx, filelock, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata, torchtext\n",
      "Successfully installed cmake-3.26.1 filelock-3.10.3 lit-16.0.0 mpmath-1.3.0 networkx-3.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sympy-1.11.1 torch-2.0.0 torchdata-0.6.0 torchtext-0.15.1 triton-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchdata torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: tqdm in /home/kach271771/Desktop/pythonenvs/lstm/lib/python3.8/site-packages (from nltk) (4.65.0)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting click\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Using cached regex-2023.3.23-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "Installing collected packages: regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.3 joblib-1.2.0 nltk-3.8.1 regex-2023.3.23\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install pandas\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.Data import loadDF, prepare_text, getPairs, toTensor, getMaxLen\n",
    "from src.Models import Seq2Seq\n",
    "from src.Vocab import Vocab\n",
    "from src.Train import train\n",
    "from src.Evaluate import evaluate\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "hidden_size = 128 # encoder and decoder hidden size\n",
    "batch_size = 128\n",
    "epochs = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/kach271771/LocalDisk/PhD/VM_data/udacity/lstmchatbot/lstm_chatbot_udacity/src/Data.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  return train_df.append(validation_df)\n"
     ]
    }
   ],
   "source": [
    "data_df = loadDF('data')\n",
    "# I will take only the first 5,000 Q&A to avoid CUDA out of memory error due to the large dataset\n",
    "data_df = data_df.iloc[:5000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? \n",
      "<  Saint Bernadette Soubirous \n",
      "\n",
      ">  What is in front of the Notre Dame Main Building? \n",
      "<  a copper statue of Christ \n",
      "\n",
      ">  The Basilica of the Sacred heart at Notre Dame is beside to which structure? \n",
      "<  the Main Building \n",
      "\n",
      ">  What is the Grotto at Notre Dame? \n",
      "<  a Marian place of prayer and reflection \n",
      "\n",
      ">  What sits on top of the Main Building at Notre Dame? \n",
      "<  a golden statue of the Virgin Mary \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5): # first 5 Q&A\n",
    "    print(\"> \", data_df.iloc[i,0], \"\\n< \", data_df.iloc[i,1], \"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df['Question'] = data_df['Question'].apply(prepare_text)\n",
    "data_df['Answer'] = data_df['Answer'].apply(prepare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pairs = getPairs(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 29)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_src, max_trg = getMaxLen(pairs)\n",
    "max_trg, max_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q_vocab = Vocab()\n",
    "A_vocab = Vocab()\n",
    "\n",
    "# build vocabularies for questions \"source\" and answers \"target\"\n",
    "for pair in pairs:\n",
    "    Q_vocab.add_words(pair[0])\n",
    "    A_vocab.add_words(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_data = [toTensor(Q_vocab, pair[0]) for pair in pairs]\n",
    "target_data = [toTensor(A_vocab, pair[1]) for pair in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/65 Epoch  -  Training Loss = 5.6954  -  Validation Loss = 5.5855\n",
      "10/65 Epoch  -  Training Loss = 5.2241  -  Validation Loss = 5.3815\n",
      "15/65 Epoch  -  Training Loss = 4.9225  -  Validation Loss = 5.0250\n",
      "20/65 Epoch  -  Training Loss = 4.4364  -  Validation Loss = 4.5959\n",
      "25/65 Epoch  -  Training Loss = 3.8199  -  Validation Loss = 4.0299\n",
      "30/65 Epoch  -  Training Loss = 3.0603  -  Validation Loss = 3.3682\n",
      "35/65 Epoch  -  Training Loss = 2.2336  -  Validation Loss = 2.6545\n",
      "40/65 Epoch  -  Training Loss = 1.4674  -  Validation Loss = 1.8930\n",
      "45/65 Epoch  -  Training Loss = 0.9090  -  Validation Loss = 1.3050\n",
      "50/65 Epoch  -  Training Loss = 0.6037  -  Validation Loss = 0.8735\n",
      "55/65 Epoch  -  Training Loss = 0.3658  -  Validation Loss = 0.5187\n",
      "60/65 Epoch  -  Training Loss = 0.2227  -  Validation Loss = 0.2932\n",
      "65/65 Epoch  -  Training Loss = 0.1606  -  Validation Loss = 0.1959\n"
     ]
    }
   ],
   "source": [
    "seq2seq = Seq2Seq(Q_vocab.words_count, hidden_size, A_vocab.words_count)\n",
    "\n",
    "train(source_data = source_data,\n",
    "      target_data = target_data,\n",
    "      model = seq2seq,\n",
    "      print_every = 5,\n",
    "      epochs = epochs,\n",
    "      learning_rate = learning_rate,\n",
    "      batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(4504, 128)\n",
       "    (lstm): LSTM(128, 128)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(4079, 128)\n",
       "    (lstm): LSTM(128, 128)\n",
       "    (fc): Linear(in_features=128, out_features=4079, bias=True)\n",
       "    (softmax): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_path = 'seq2seq.pt'\n",
    "\n",
    "torch.save(seq2seq, model_path)\n",
    "\n",
    "seq2seq = torch.load(model_path, map_location=torch.device('cuda'))\n",
    "seq2seq.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'exit' to finish the chat.\n",
      " ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  What is the Grotto at Notre Dame? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< a marian place of art and prayer \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  exit\n"
     ]
    }
   ],
   "source": [
    "print(\"Type 'exit' to finish the chat.\\n\", \"-\"*30, '\\n')\n",
    "while (True):\n",
    "    src = input(\"> \")\n",
    "    if src.strip() == \"exit\":\n",
    "        break\n",
    "    evaluate(src, Q_vocab, A_vocab, seq2seq, max_trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Starter Code) LSTM Bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
